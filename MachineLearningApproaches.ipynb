{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import re\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler()\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cross_validation import  cross_val_score\n",
    "import time\n",
    "from sklearn.datasets import  load_iris\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score,confusion_matrix\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"NepaliEarthquakeTweets_plus_blockade.xlsx\",sheetname=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_indexes = np.where(data['bhawna']=='p')\n",
    "neg_indexes = np.where(data['bhawna']=='n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "605"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(neg_indexes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_indexes = np.where(data['bhawna']=='p')\n",
    "neg_indexes = np.where(data['bhawna']=='n')\n",
    "size = 500\n",
    "df_pos = pd.DataFrame.from_items([('text',data['tweet_text'][pos_indexes[0][0:size]]),('target',0)])\n",
    "df_neg = pd.DataFrame.from_items([('text',data['tweet_text'][neg_indexes[0][0:size]]),('target',1)])\n",
    "\n",
    "df_pos['tweet_id'] = data['tweet_id'][pos_indexes[0][0:size]]\n",
    "df_pos['reply'] = data['reply'][pos_indexes[0][0:size]]\n",
    "df_pos['retweet'] = data['retweet'][pos_indexes[0][0:size]]\n",
    "df_pos['likes'] = data['likes'][pos_indexes[0][0:size]]\n",
    "#df_pos['emoji'] = data['emoji'][pos_indexes[0][0:size]]\n",
    "df_pos['bhawna']=data['bhawna'][pos_indexes[0][0:size]]\n",
    "\n",
    "df_neg['tweet_id'] = data['tweet_id'][neg_indexes[0][0:size]]\n",
    "df_neg['reply'] = data['reply'][neg_indexes[0][0:size]]\n",
    "df_neg['retweet'] = data['retweet'][neg_indexes[0][0:size]]\n",
    "df_neg['likes'] = data['likes'][neg_indexes[0][0:size]]\n",
    "#df_neg['emoji'] = data['emoji'][neg_indexes[0][0:size]]\n",
    "df_neg['bhawna']=data['bhawna'][neg_indexes[0][0:size]]\n",
    "\n",
    "\n",
    "df_pos.index = range(len(df_pos.index))\n",
    "df_neg.index = range(len(df_neg.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_df_F= df_pos[500:600]\n",
    "validation_df_F = validation_df_F.append(df_neg[500:600])\n",
    "validation_df_F.index = range(len(validation_df_F.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing necessary Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def normalize(X):\n",
    "    #print(X)\n",
    "    if(max(X)==0 and min(X)==0):\n",
    "        return X\n",
    "    return [((x-min(X))/(max(X)-min(X))) for x in X]\n",
    "#print(normalize(X))\n",
    "def count_urls(text):\n",
    "    urls = re.findall('https?://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+', text)\n",
    "    return len(urls)\n",
    "def count_hashtags(text):\n",
    "    hashtags = re.findall(r\"#(\\w+)\", text)\n",
    "    return len(hashtags)\n",
    "def count_user_mentions(text):\n",
    "    user_mentions = re.findall(r\"@(\\w+)\", text)\n",
    "    return len(user_mentions)\n",
    "def count_unique_characters(text):\n",
    "    return len(list(set(text)))\n",
    "from string import punctuation\n",
    "def count_special_characters(text):\n",
    "    sc = [p for p in text if p in punctuation]\n",
    "    return len(sc)\n",
    "def get_words(text):\n",
    "    words = text.replace(\",\",\" \").replace(\". \",\" \").strip().split()\n",
    "    return words\n",
    "def count_words(text):\n",
    "    words = get_words(text)\n",
    "    return len(words)\n",
    "slangwords = pd.read_excel('SlangWordsForNepali.xlsx')\n",
    "for index in range(0,len(data['slangwords'])):\n",
    "    w = data['slangwords'][index]\n",
    "    w = str(w).rstrip().strip()\n",
    "    if(w!='nan' and len(w)>0):\n",
    "        words = w.split(\",\")\n",
    "        for w1 in words:\n",
    "            w1 = w1.rstrip().strip()\n",
    "            if(w1 not in slangwords['Nepali'] and len(w1)>0):\n",
    "                slangwords=slangwords.append({'Roman English':'','Nepali':w1,'English':'','Meaning':''},ignore_index=True)\n",
    "def count_slangwords(text):\n",
    "    sw = [w for w in get_words(text) if (len(np.where(slangwords['Nepali']==w)[0].tolist())>0)]\n",
    "    return len(sw)\n",
    "stopwords = pd.read_csv('nepali_stopwords.txt')\n",
    "def count_stopwords(text):\n",
    "    sw = [w for w in get_words(text) if (len(np.where(stopwords['stopwords']==w)[0].tolist())>0)]\n",
    "    return len(sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slangwords = pd.read_excel('SlangWordsForNepali.xlsx')\n",
    "for index in range(0,len(data['slangwords'])):\n",
    "    w = data['slangwords'][index]\n",
    "    w = str(w).rstrip().strip()\n",
    "    if(w!='nan' and len(w)>0):\n",
    "        words = w.split(\",\")\n",
    "        for w1 in words:\n",
    "            w1 = w1.rstrip().strip()\n",
    "            if(w1 not in slangwords['Nepali'] and len(w1)>0):\n",
    "                slangwords=slangwords.append({'Roman English':'','Nepali':w1,'English':'','Meaning':''},ignore_index=True)\n",
    "len(slangwords)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Urdu to English Dictionary Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import MySQLdb\n",
    "db = MySQLdb.connect(\"localhost\",\"root\",\"\",\"nepal_earthquak_2015_tweets\",use_unicode=True, charset=\"utf8\")\n",
    "cursor = db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary = pd.read_excel(\"dictionary.xlsx\",sheetname=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w='hello'\n",
    "adjective = []\n",
    "#if(len(exist)==1 and 'adjective' in dictionary['POS'][exist[0]]):\n",
    "#    print(\"Word: \"+w+\" is adjective\")\n",
    "exist = np.where(dictionary['Nepali Converted']==w)[0].tolist()\n",
    "adjective.append([w for index in exist if('adjective' in dictionary['POS'][index])])\n",
    "#dictionary['POS'][exist]\n",
    "adjective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Roman Nepali</th>\n",
       "      <th>Nepali</th>\n",
       "      <th>Nepali Converted</th>\n",
       "      <th>POS</th>\n",
       "      <th>Meaning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aba</td>\n",
       "      <td>ca</td>\n",
       "      <td>अब</td>\n",
       "      <td>Adverb;</td>\n",
       "      <td>now, from now on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abaddha</td>\n",
       "      <td>cfa$</td>\n",
       "      <td>आबद्ध</td>\n",
       "      <td>Noun;/adjective;</td>\n",
       "      <td>bound, tied up confined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abela</td>\n",
       "      <td>ca]nf</td>\n",
       "      <td>अबेला</td>\n",
       "      <td>Noun;/adjective;</td>\n",
       "      <td>lateness, late</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aber</td>\n",
       "      <td>ca]/</td>\n",
       "      <td>अबेर</td>\n",
       "      <td>adjective;</td>\n",
       "      <td>Late</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aber bhayo</td>\n",
       "      <td>ca]/ eof]</td>\n",
       "      <td>अबेर भयो</td>\n",
       "      <td>compound</td>\n",
       "      <td>it is late</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>abhas</td>\n",
       "      <td>cfef;</td>\n",
       "      <td>आभास</td>\n",
       "      <td>Noun;</td>\n",
       "      <td>glimpse, shadow, reflection, vision, faint mem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>abhav</td>\n",
       "      <td>cefj</td>\n",
       "      <td>अभाव</td>\n",
       "      <td>Noun;</td>\n",
       "      <td>non-existence, absence, lack, scarcity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>abhaya</td>\n",
       "      <td>ceo</td>\n",
       "      <td>अभय</td>\n",
       "      <td>Noun;</td>\n",
       "      <td>lack of fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>abhibhavak</td>\n",
       "      <td>cleefjs</td>\n",
       "      <td>अभिभावक</td>\n",
       "      <td>Noun;</td>\n",
       "      <td>guardian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>abhilekh</td>\n",
       "      <td>clen]v</td>\n",
       "      <td>अभिलेख</td>\n",
       "      <td>Noun;</td>\n",
       "      <td>inscription</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>abhinaya</td>\n",
       "      <td>clego</td>\n",
       "      <td>अभिनय</td>\n",
       "      <td>Noun;</td>\n",
       "      <td>mimicry, imitation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>abhiprerit</td>\n",
       "      <td>clek|]l/t</td>\n",
       "      <td>अभिप्रेरित</td>\n",
       "      <td>adjective;</td>\n",
       "      <td>motivated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>abhipret</td>\n",
       "      <td>clek|]t</td>\n",
       "      <td>अभिप्रेत</td>\n",
       "      <td>adjective;</td>\n",
       "      <td>planned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>abhiram</td>\n",
       "      <td>cle/fd</td>\n",
       "      <td>अभिराम</td>\n",
       "      <td>adjective;</td>\n",
       "      <td>extremely beautiful, sublime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>abhiruci</td>\n",
       "      <td>cle?lr</td>\n",
       "      <td>अभिरुचि</td>\n",
       "      <td>Noun;</td>\n",
       "      <td>inclination, earnest desire, liking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>abhivriddhi</td>\n",
       "      <td>clej[l$</td>\n",
       "      <td>अभिवृद्धि</td>\n",
       "      <td>Noun;</td>\n",
       "      <td>development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>abhiyan</td>\n",
       "      <td>cleofg</td>\n",
       "      <td>अभियान</td>\n",
       "      <td>Noun;</td>\n",
       "      <td>expedition, march, exploration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>abhiyog</td>\n",
       "      <td>cleof]u</td>\n",
       "      <td>अभियोग</td>\n",
       "      <td>Noun;</td>\n",
       "      <td>accusation, allegation, charge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>abhiyukta</td>\n",
       "      <td>cleoÚQm</td>\n",
       "      <td>अभियुक्त</td>\n",
       "      <td>adjective;</td>\n",
       "      <td>accused</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>abhrak</td>\n",
       "      <td>ce|s</td>\n",
       "      <td>अभ्रक</td>\n",
       "      <td>Noun;</td>\n",
       "      <td>mica, talco (a soft mineral)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>abhyas</td>\n",
       "      <td>cEof;</td>\n",
       "      <td>अभ्यास</td>\n",
       "      <td>Noun;</td>\n",
       "      <td>practice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>abrak</td>\n",
       "      <td>ce|v</td>\n",
       "      <td>अभ्रख</td>\n",
       "      <td>Noun;</td>\n",
       "      <td>mica, talco (a soft mineral)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>acamma</td>\n",
       "      <td>crDd</td>\n",
       "      <td>अचम्म</td>\n",
       "      <td>Noun;</td>\n",
       "      <td>surprise, wonder, amazement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>acamma lagnu</td>\n",
       "      <td>crDd nfUgÚ</td>\n",
       "      <td>अचम्मा लगनु</td>\n",
       "      <td>VERB i.;</td>\n",
       "      <td>to be surprised, to be amazed, to be astonished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>acamma parnu</td>\n",
       "      <td>crDd kgÚ{</td>\n",
       "      <td>अचम्मा पर्नु</td>\n",
       "      <td>VERB i.;</td>\n",
       "      <td>to be surprised, to be amazed, to be astonished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>acamma parnu</td>\n",
       "      <td>crDd kgÚ{</td>\n",
       "      <td>अचम्मा पर्नु</td>\n",
       "      <td>VERB t.;</td>\n",
       "      <td>to surprise, to amaze, to astonish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>acanak</td>\n",
       "      <td>crfgs</td>\n",
       "      <td>अचानक</td>\n",
       "      <td>Adverb;</td>\n",
       "      <td>suddenly, abruptly, unexpectedly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>acano</td>\n",
       "      <td>crfgf]</td>\n",
       "      <td>अचानो</td>\n",
       "      <td>Noun;</td>\n",
       "      <td>cutting board for meat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>acanu</td>\n",
       "      <td>crfgÚ</td>\n",
       "      <td>अचानु</td>\n",
       "      <td>Noun;</td>\n",
       "      <td>cutting board for meat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>acar</td>\n",
       "      <td>crf/</td>\n",
       "      <td>अचार</td>\n",
       "      <td>Noun;</td>\n",
       "      <td>hot and sour pickle, pickles, chutney, salsa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4340</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>त्यस बाहेक</td>\n",
       "      <td>preposition</td>\n",
       "      <td>in addition to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4341</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>त्यसको अगाडि</td>\n",
       "      <td>preposition</td>\n",
       "      <td>in front of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4342</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>त्यो हुँदा हुँदै पनि</td>\n",
       "      <td>preposition</td>\n",
       "      <td>in spite of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4343</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>तर्फबाट</td>\n",
       "      <td>preposition</td>\n",
       "      <td>on behalf of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4344</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>माथि</td>\n",
       "      <td>preposition</td>\n",
       "      <td>on top of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4345</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>सर्वनाम</td>\n",
       "      <td>Pronoun;</td>\n",
       "      <td>Pronouns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4346</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>म</td>\n",
       "      <td>Pronoun;</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4347</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>तिमी</td>\n",
       "      <td>Pronoun;</td>\n",
       "      <td>you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4348</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>उ</td>\n",
       "      <td>Pronoun;</td>\n",
       "      <td>he</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4349</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>तिनी</td>\n",
       "      <td>Pronoun;</td>\n",
       "      <td>she</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4350</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>हामी</td>\n",
       "      <td>Pronoun;</td>\n",
       "      <td>we</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4351</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>तिनीहरू</td>\n",
       "      <td>Pronoun;</td>\n",
       "      <td>they</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4352</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>म</td>\n",
       "      <td>Pronoun;</td>\n",
       "      <td>me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4353</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>तिमी</td>\n",
       "      <td>Pronoun;</td>\n",
       "      <td>you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4354</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>उ</td>\n",
       "      <td>Pronoun;</td>\n",
       "      <td>him</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4355</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>उनको</td>\n",
       "      <td>Pronoun;</td>\n",
       "      <td>her</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4356</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>हामी</td>\n",
       "      <td>Pronoun;</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4357</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>तिनीहरू</td>\n",
       "      <td>Pronoun;</td>\n",
       "      <td>them</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4358</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>मेरो</td>\n",
       "      <td>Pronoun;</td>\n",
       "      <td>my</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4359</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>तिम्रो</td>\n",
       "      <td>Pronoun;</td>\n",
       "      <td>your</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4360</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>उस्को</td>\n",
       "      <td>Pronoun;</td>\n",
       "      <td>his</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4361</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>तिनको</td>\n",
       "      <td>Pronoun;</td>\n",
       "      <td>her</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4362</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>हाम्रो</td>\n",
       "      <td>Pronoun;</td>\n",
       "      <td>our</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4363</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>तिनीहरूको</td>\n",
       "      <td>Pronoun;</td>\n",
       "      <td>their</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4364</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>मेरो</td>\n",
       "      <td>Pronoun;</td>\n",
       "      <td>mine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4365</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>तिम्रो</td>\n",
       "      <td>Pronoun;</td>\n",
       "      <td>yours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4366</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>उस्को</td>\n",
       "      <td>Pronoun;</td>\n",
       "      <td>his</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4367</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>उनको</td>\n",
       "      <td>Pronoun;</td>\n",
       "      <td>hers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4368</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>हाम्रो</td>\n",
       "      <td>Pronoun;</td>\n",
       "      <td>ours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4369</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>तिनीहरूको</td>\n",
       "      <td>Pronoun;</td>\n",
       "      <td>theirs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4370 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Roman Nepali      Nepali      Nepali Converted               POS  \\\n",
       "0              aba          ca                    अब           Adverb;   \n",
       "1          abaddha        cfa$                 आबद्ध  Noun;/adjective;   \n",
       "2            abela       ca]nf                 अबेला  Noun;/adjective;   \n",
       "3             aber        ca]/                  अबेर        adjective;   \n",
       "4       aber bhayo   ca]/ eof]              अबेर भयो          compound   \n",
       "5            abhas       cfef;                  आभास             Noun;   \n",
       "6            abhav        cefj                  अभाव             Noun;   \n",
       "7           abhaya         ceo                   अभय             Noun;   \n",
       "8       abhibhavak     cleefjs               अभिभावक             Noun;   \n",
       "9         abhilekh      clen]v                अभिलेख             Noun;   \n",
       "10        abhinaya       clego                 अभिनय             Noun;   \n",
       "11      abhiprerit   clek|]l/t            अभिप्रेरित        adjective;   \n",
       "12        abhipret     clek|]t              अभिप्रेत        adjective;   \n",
       "13         abhiram      cle/fd                अभिराम        adjective;   \n",
       "14        abhiruci      cle?lr               अभिरुचि             Noun;   \n",
       "15     abhivriddhi     clej[l$             अभिवृद्धि             Noun;   \n",
       "16         abhiyan      cleofg                अभियान             Noun;   \n",
       "17         abhiyog     cleof]u                अभियोग             Noun;   \n",
       "18       abhiyukta     cleoÚQm              अभियुक्त        adjective;   \n",
       "19          abhrak        ce|s                 अभ्रक             Noun;   \n",
       "20          abhyas       cEof;                अभ्यास             Noun;   \n",
       "21           abrak        ce|v                 अभ्रख             Noun;   \n",
       "22          acamma        crDd                 अचम्म             Noun;   \n",
       "23    acamma lagnu  crDd nfUgÚ           अचम्मा लगनु          VERB i.;   \n",
       "24    acamma parnu   crDd kgÚ{          अचम्मा पर्नु          VERB i.;   \n",
       "25    acamma parnu   crDd kgÚ{          अचम्मा पर्नु          VERB t.;   \n",
       "26          acanak       crfgs                 अचानक           Adverb;   \n",
       "27           acano      crfgf]                 अचानो             Noun;   \n",
       "28           acanu       crfgÚ                 अचानु             Noun;   \n",
       "29            acar        crf/                  अचार             Noun;   \n",
       "...            ...         ...                   ...               ...   \n",
       "4340           NaN         NaN            त्यस बाहेक       preposition   \n",
       "4341           NaN         NaN          त्यसको अगाडि       preposition   \n",
       "4342           NaN         NaN  त्यो हुँदा हुँदै पनि       preposition   \n",
       "4343           NaN         NaN               तर्फबाट       preposition   \n",
       "4344           NaN         NaN                  माथि       preposition   \n",
       "4345           NaN         NaN               सर्वनाम          Pronoun;   \n",
       "4346           NaN         NaN                     म          Pronoun;   \n",
       "4347           NaN         NaN                  तिमी          Pronoun;   \n",
       "4348           NaN         NaN                     उ          Pronoun;   \n",
       "4349           NaN         NaN                  तिनी          Pronoun;   \n",
       "4350           NaN         NaN                  हामी          Pronoun;   \n",
       "4351           NaN         NaN               तिनीहरू          Pronoun;   \n",
       "4352           NaN         NaN                     म          Pronoun;   \n",
       "4353           NaN         NaN                  तिमी          Pronoun;   \n",
       "4354           NaN         NaN                     उ          Pronoun;   \n",
       "4355           NaN         NaN                  उनको          Pronoun;   \n",
       "4356           NaN         NaN                  हामी          Pronoun;   \n",
       "4357           NaN         NaN               तिनीहरू          Pronoun;   \n",
       "4358           NaN         NaN                  मेरो          Pronoun;   \n",
       "4359           NaN         NaN                तिम्रो          Pronoun;   \n",
       "4360           NaN         NaN                 उस्को          Pronoun;   \n",
       "4361           NaN         NaN                 तिनको          Pronoun;   \n",
       "4362           NaN         NaN                हाम्रो          Pronoun;   \n",
       "4363           NaN         NaN             तिनीहरूको          Pronoun;   \n",
       "4364           NaN         NaN                  मेरो          Pronoun;   \n",
       "4365           NaN         NaN                तिम्रो          Pronoun;   \n",
       "4366           NaN         NaN                 उस्को          Pronoun;   \n",
       "4367           NaN         NaN                  उनको          Pronoun;   \n",
       "4368           NaN         NaN                हाम्रो          Pronoun;   \n",
       "4369           NaN         NaN             तिनीहरूको          Pronoun;   \n",
       "\n",
       "                                                Meaning  \n",
       "0                                      now, from now on  \n",
       "1                               bound, tied up confined  \n",
       "2                                        lateness, late  \n",
       "3                                                  Late  \n",
       "4                                            it is late  \n",
       "5     glimpse, shadow, reflection, vision, faint mem...  \n",
       "6                non-existence, absence, lack, scarcity  \n",
       "7                                          lack of fear  \n",
       "8                                              guardian  \n",
       "9                                           inscription  \n",
       "10                                   mimicry, imitation  \n",
       "11                                            motivated  \n",
       "12                                              planned  \n",
       "13                         extremely beautiful, sublime  \n",
       "14                  inclination, earnest desire, liking  \n",
       "15                                          development  \n",
       "16                       expedition, march, exploration  \n",
       "17                       accusation, allegation, charge  \n",
       "18                                              accused  \n",
       "19                         mica, talco (a soft mineral)  \n",
       "20                                             practice  \n",
       "21                         mica, talco (a soft mineral)  \n",
       "22                          surprise, wonder, amazement  \n",
       "23      to be surprised, to be amazed, to be astonished  \n",
       "24      to be surprised, to be amazed, to be astonished  \n",
       "25                   to surprise, to amaze, to astonish  \n",
       "26                     suddenly, abruptly, unexpectedly  \n",
       "27                               cutting board for meat  \n",
       "28                               cutting board for meat  \n",
       "29         hot and sour pickle, pickles, chutney, salsa  \n",
       "...                                                 ...  \n",
       "4340                                     in addition to  \n",
       "4341                                        in front of  \n",
       "4342                                        in spite of  \n",
       "4343                                       on behalf of  \n",
       "4344                                          on top of  \n",
       "4345                                           Pronouns  \n",
       "4346                                                  I  \n",
       "4347                                                you  \n",
       "4348                                                 he  \n",
       "4349                                                she  \n",
       "4350                                                 we  \n",
       "4351                                               they  \n",
       "4352                                                 me  \n",
       "4353                                                you  \n",
       "4354                                                him  \n",
       "4355                                                her  \n",
       "4356                                                 us  \n",
       "4357                                               them  \n",
       "4358                                                 my  \n",
       "4359                                               your  \n",
       "4360                                                his  \n",
       "4361                                                her  \n",
       "4362                                                our  \n",
       "4363                                              their  \n",
       "4364                                               mine  \n",
       "4365                                              yours  \n",
       "4366                                                his  \n",
       "4367                                               hers  \n",
       "4368                                               ours  \n",
       "4369                                             theirs  \n",
       "\n",
       "[4370 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing function for formality feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formality = (#nouns + #adjectives + #prepositions + #articles - #pronouns- #verbs - #adverbs - #interjections + 100)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"एउटाले केन्द्र गोर्खा भन्छ/अर्कोले केन्द्र लमजुङ भन्छ! हैन योSLCको परिक्षा केन्द्र जस्तो हो कि क्या हो?एकैपटक जताकतै हुने?#NepalEarthquake\"\n",
    "#text = \"आज बिहान ३:२३ मा गएको भुकम्प: ५.० रेक्टरस्केल केन्द्र गोरखा। #NepalEarthquake\"\n",
    "#print(\"Tweets: \"+text)\n",
    "def count_nouns(text):\n",
    "    words = get_words(text)\n",
    "    nouns = []\n",
    "    for w in words:\n",
    "        #query1 = \"SELECT meaning,pos FROM `urdu_english_dictionary` where word ='\"+w+\"' and (pos like '%noun%' or pos like 'noun%' or pos like '%noun') and not (pos like '%adjective%' or pos like '%adjective' or pos like 'adjective%') and not (pos like '%preposition%' or pos like 'preposition%' or pos like '%preposition') and not (pos like '%article%' or pos like 'article%' or pos like '%article') and not (pos like '%pronoun%' or pos like 'pronoun%' or pos like '%pronoun') and not (pos like '%verb%' or pos like 'verb%' or pos like '%verb') and not (pos like '%adverb%' or pos like 'adverb%' or pos like '%adverb') and not (pos like '%interjection%' or pos like 'interjection%' or pos like '%interjection')\"\n",
    "        #query1 = \"SELECT meaning,pos FROM `nepali_english_dictionary` where word ='\"+w+\"' and (pos like '%noun%' or pos like 'noun%' or pos like '%noun')\"\n",
    "        query1 = \"SELECT * FROM `table 8` where word='\"+w+ \"' and pos = 'सङ्. ना.' or pos = 'असङ्. ना.' or pos ='ना.' or pos = 'संवा.'\"\n",
    "        #print(\"Query: \"+query1)\n",
    "        cursor.execute(query1)\n",
    "        exist = cursor.fetchall()\n",
    "        if(len(exist)>0):\n",
    "            nouns.append(w)\n",
    "        '''if(len(exist)==0):\n",
    "            exist = np.where(dictionary['Nepali Converted']==w)[0].tolist()\n",
    "            #print(exist)\n",
    "            #print(\"Word: \"+w)\n",
    "            if(len(exist)>0 and str(dictionary['POS'][exist[0]])!='nan' and 'Noun' in dictionary['POS'][exist[0]]):\n",
    "                nouns.append(w)'''\n",
    "          #temp = [w for index in exist if('noun' in dictionary['POS'][index])]\n",
    "                #nouns.append(tw)\n",
    "    #print(\"Nouns:\")\n",
    "    #print(nouns)\n",
    "    return(len(nouns))\n",
    "\n",
    "def count_adjectives(text):\n",
    "    words = get_words(text)\n",
    "    adjectives = []\n",
    "    for w in words:\n",
    "        #query1 = \"SELECT meaning,pos FROM `urdu_english_dictionary` where word ='\"+w+\"' and not (pos like '%noun%' or pos like 'noun%' or pos like '%noun') and (pos like '%adjective%' or pos like '%adjective' or pos like 'adjective%') and not (pos like '%preposition%' or pos like 'preposition%' or pos like '%preposition') and not (pos like '%article%' or pos like 'article%' or pos like '%article') and not (pos like '%pronoun%' or pos like 'pronoun%' or pos like '%pronoun') and not (pos like '%verb%' or pos like 'verb%' or pos like '%verb') and not (pos like '%adverb%' or pos like 'adverb%' or pos like '%adverb') and not (pos like '%interjection%' or pos like 'interjection%' or pos like '%interjection')\"\n",
    "        ##query1 = \"SELECT meaning,pos FROM `nepali_english_dictionary` where word ='\"+w+\"' and (pos like '%adjective%' or pos like 'adjective%' or pos like '%adjective')\"\n",
    "        query1 = \"SELECT * FROM `table 8` where word='\"+w+ \"' and pos like '%वि. ' or pos like '%वि.'\" \n",
    "        cursor.execute(query1)\n",
    "        exist = cursor.fetchall()\n",
    "        if(len(exist)>0):\n",
    "            adjectives.append(w)\n",
    "        '''if(len(exist)==0):\n",
    "            exist = np.where(dictionary['Nepali Converted']==w)[0].tolist()\n",
    "            if(len(exist)>0 and str(dictionary['POS'][exist[0]])!='nan' and 'adjective' in dictionary['POS'][exist[0]]):\n",
    "                adjectives.append(w)'''\n",
    "            #temp = [w for index in exist if('adjective' in dictionary['POS'][index])]\n",
    "            #for tw in temp:\n",
    "                #adjectives.append(tw)\n",
    "    #print(\"Adjectives\")\n",
    "    #print(adjectives)\n",
    "    return(len(adjectives))\n",
    "\n",
    "def count_prepositions(text):\n",
    "    words = get_words(text)\n",
    "    prepositions = []\n",
    "    for w in words:\n",
    "        #query1 = \"SELECT meaning,pos FROM `urdu_english_dictionary` where word ='\"+w+\"' and not (pos like '%noun%' or pos like 'noun%' or pos like '%noun') and not (pos like '%adjective%' or pos like '%adjective' or pos like 'adjective%') and (pos like '%preposition%' or pos like 'preposition%' or pos like '%preposition') and not (pos like '%article%' or pos like 'article%' or pos like '%article') and not (pos like '%pronoun%' or pos like 'pronoun%' or pos like '%pronoun') and not (pos like '%verb%' or pos like 'verb%' or pos like '%verb') and not (pos like '%adverb%' or pos like 'adverb%' or pos like '%adverb') and not (pos like '%interjection%' or pos like 'interjection%' or pos like '%interjection')\"\n",
    "        #query1 = \"SELECT meaning,pos FROM `nepali_english_dictionary` where word ='\"+w+\"' and (pos like '%preposition%' or pos like 'preposition%' or pos like '%preposition')\"\n",
    "        query1=\"SELECT * FROM `table 8` where word = '\"+w+\"' and pos =' नायो.' \"\n",
    "        #print(\"Query: \"+query1)\n",
    "        cursor.execute(query1)\n",
    "        exist = cursor.fetchall()\n",
    "        if(len(exist)>0):\n",
    "            prepositions.append(w)\n",
    "        '''if(len(exist)==0):\n",
    "            exist = np.where(dictionary['Nepali Converted']==w)[0].tolist()\n",
    "            if(len(exist)>0 and str(dictionary['POS'][exist[0]])!='nan' and'preposition' in dictionary['POS'][exist[0]]):\n",
    "                prepositions.append(w)\n",
    "            #temp = [w for index in exist if('preposition' in dictionary['POS'][index])]\n",
    "            #for tw in temp:\n",
    "                #prepositions.append(tw)'''\n",
    "    #print(\"Prepositions\")\n",
    "    #print(prepositions)\n",
    "    return(len(prepositions))\n",
    "\n",
    "def count_pronouns(text):\n",
    "    words = get_words(text)\n",
    "    pronouns = []\n",
    "    for w in words:\n",
    "        #query1 = \"SELECT meaning,pos FROM `urdu_english_dictionary` where word ='\"+w+\"' and not (pos like '%noun%' or pos like 'noun%' or pos like '%noun') and not (pos like '%adjective%' or pos like '%adjective' or pos like 'adjective%') and not (pos like '%preposition%' or pos like 'preposition%' or pos like '%preposition') and not (pos like '%article%' or pos like 'article%' or pos like '%article') and (pos like '%pronoun%' or pos like 'pronoun%' or pos like '%pronoun') and not (pos like '%verb%' or pos like 'verb%' or pos like '%verb') and not (pos like '%adverb%' or pos like 'adverb%' or pos like '%adverb') and not (pos like '%interjection%' or pos like 'interjection%' or pos like '%interjection')\"\n",
    "        #query1 = \"SELECT meaning,pos FROM `nepali_english_dictionary` where word ='\"+w+\"' and (pos like '%pronoun%' or pos like 'pronoun%' or pos like '%pronoun')\"\n",
    "        query1=\"SELECT * FROM `table 8` where word = '\"+w+\"' and pos like '% स.'\"\n",
    "        #print(\"Query: \"+query1)\n",
    "        cursor.execute(query1)\n",
    "        exist = cursor.fetchall()\n",
    "        if(len(exist)>0):\n",
    "            pronouns.append(w)\n",
    "        '''if(len(exist)==0):\n",
    "            exist = np.where(dictionary['Nepali Converted']==w)[0].tolist()\n",
    "            if(len(exist)>0 and str(dictionary['POS'][exist[0]])!='nan' and 'pronoun' in dictionary['POS'][exist[0]]):\n",
    "                pronouns.append()'''\n",
    "            #temp = [w for index in exist if('pronoun' in dictionary['POS'][index])]\n",
    "            #for tw in temp:\n",
    "                #pronouns.append(tw)\n",
    "    #print(\"Pronouns\")\n",
    "    #print(pronouns)\n",
    "    return(len(pronouns))\n",
    "\n",
    "def count_verbs(text):\n",
    "    words = get_words(text)\n",
    "    verbs = []\n",
    "    for w in words:\n",
    "        #query1 = \"SELECT meaning,pos FROM `urdu_english_dictionary` where word ='\"+w+\"' and not (pos like '%noun%' or pos like 'noun%' or pos like '%noun') and not (pos like '%adjective%' or pos like '%adjective' or pos like 'adjective%') and not (pos like '%preposition%' or pos like 'preposition%' or pos like '%preposition') and not (pos like '%article%' or pos like 'article%' or pos like '%article') and not (pos like '%pronoun%' or pos like 'pronoun%' or pos like '%pronoun') and (pos like '%verb%' or pos like 'verb%' or pos like '%verb') and not (pos like '%adverb%' or pos like 'adverb%' or pos like '%adverb') and not (pos like '%interjection%' or pos like 'interjection%' or pos like '%interjection')\"\n",
    "        #query1 = \"SELECT meaning,pos FROM `nepali_english_dictionary` where word ='\"+w+\"' and (pos like '%verb%' or pos like 'verb%' or pos like '%verb')\"   \n",
    "        query1 = \"SELECT * FROM `table 8`  where word = '\"+w+\"' and  pos like '%क्रि.'\"\n",
    "        #print(\"Query: \"+query1)\n",
    "        cursor.execute(query1)\n",
    "        exist = cursor.fetchall()\n",
    "        if(len(exist)>0):\n",
    "            verbs.append(w)\n",
    "        '''if(len(exist)==0):\n",
    "            exist = np.where(dictionary['Nepali Converted']==w)[0].tolist()\n",
    "            if(len(exist)>0 and str(dictionary['POS'][exist[0]])!='nan' and 'VERB ' in dictionary['POS'][exist[0]]):\n",
    "                verbs.append(w)'''\n",
    "    #print(\"Verbs\")\n",
    "    #print(verbs)\n",
    "    return(len(verbs))\n",
    "\n",
    "def count_adverbs(text):\n",
    "    words = get_words(text)\n",
    "    adverbs = []\n",
    "    for w in words:\n",
    "        #query1 = \"SELECT meaning,pos FROM `urdu_english_dictionary` where word ='\"+w+\"' and not (pos like '%noun%' or pos like 'noun%' or pos like '%noun') and not (pos like '%adjective%' or pos like '%adjective' or pos like 'adjective%') and not (pos like '%preposition%' or pos like 'preposition%' or pos like '%preposition') and not (pos like '%article%' or pos like 'article%' or pos like '%article') and not (pos like '%pronoun%' or pos like 'pronoun%' or pos like '%pronoun') and not (pos like '%verb%' or pos like 'verb%' or pos like '%verb') and (pos like '%adverb%' or pos like 'adverb%' or pos like '%adverb') and not (pos like '%interjection%' or pos like 'interjection%' or pos like '%interjection')\"\n",
    "        #query1 = \"SELECT meaning,pos FROM `nepali_english_dictionary` where word ='\"+w+\"' and (pos like '%adverb%' or pos like 'adverb%' or pos like '%adverb')\"\n",
    "        query1 = \"SELECT * FROM `table 8`  where word = '\"+w+\"' and  pos like '%क्रियो.' or pos like '%क्रियो. '\"\n",
    "        #print(\"Query: \"+query1)\n",
    "        cursor.execute(query1)\n",
    "        exist = cursor.fetchall()\n",
    "        if(len(exist)>0):\n",
    "            adverbs.append(w)\n",
    "        '''if(len(exist)==0):\n",
    "            exist = np.where(dictionary['Nepali Converted']==w)[0].tolist()\n",
    "            if(len(exist)>0 and str(dictionary['POS'][exist[0]])!='nan' and 'adverb' in dictionary['POS'][exist[0]]):\n",
    "                adverbs.append(w)'''\n",
    "    #print(\"Adverbs\")\n",
    "    #print(adverbs)\n",
    "    return(len(adverbs))\n",
    "\n",
    "def count_conjunctions(text):\n",
    "    words = get_words(text)\n",
    "    conjunction = []\n",
    "    for w in words:\n",
    "        #query1 = \"SELECT meaning,pos FROM `urdu_english_dictionary` where word ='\"+w+\"' and not (pos like '%noun%' or pos like 'noun%' or pos like '%noun') and not (pos like '%adjective%' or pos like '%adjective' or pos like 'adjective%') and not (pos like '%preposition%' or pos like 'preposition%' or pos like '%preposition') and not (pos like '%article%' or pos like 'article%' or pos like '%article') and not (pos like '%pronoun%' or pos like 'pronoun%' or pos like '%pronoun') and not (pos like '%verb%' or pos like 'verb%' or pos like '%verb') and not (pos like '%adverb%' or pos like 'adverb%' or pos like '%adverb') and (pos like '%interjection%' or pos like 'interjection%' or pos like '%interjection')\"\n",
    "        #query1 = \"SELECT meaning,pos FROM `nepali_english_dictionary` where word ='\"+w+\"' and (pos like '%conjunction%' or pos like 'conjunction%' or pos like '%conjunction')\"\n",
    "        query1 = \"SELECT * FROM `table 8`  where word = '\"+w+\"' and pos like '%सं.'\"\n",
    "        cursor.execute(query1)\n",
    "        exist = cursor.fetchall()\n",
    "        if(len(exist)>0):\n",
    "            conjunction.append(w)\n",
    "        '''if(len(exist)==0):\n",
    "            exist = np.where(dictionary['Nepali Converted']==w)[0].tolist()\n",
    "            if(len(exist)>0 and str(dictionary['POS'][exist[0]])!='nan' and 'conjunction' in dictionary['POS'][exist[0]]):\n",
    "                conjunction.append(w)'''\n",
    "    #print(\"conjunction\")\n",
    "    #print(conjunction)\n",
    "    return(len(conjunction))\n",
    "#count_nouns(text)            \n",
    "#count_adjectives(text)  \n",
    "#count_prepositions(text)\n",
    "#count_pronouns(text)\n",
    "#count_verbs(text)\n",
    "#count_adverbs(text)\n",
    "#count_conjunctions(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat1 = r'@[A-Za-z0-9]+'\n",
    "pat2 = r'https?://[A-Za-z0-9./]+'\n",
    "pat3 = r'([@#][A-Za-z0-9]+)'\n",
    "pat4 = r'.[A-Za-z0-9./]+'\n",
    "pat5 = r'[\\,۔،۔”–’‘‘_!…।-]|(\")|(:)|(%)|(ः)|(\\u200d)|(\\xa0…)|(\\u200c\\u200c)'\n",
    "combined_pat = r'|'.join((pat1, pat2,pat3,pat4,pat5))\n",
    "\n",
    "df_pos['nouns']=[count_nouns(re.sub(combined_pat, ' ', text).strip().rstrip()) for text in df_pos['text']]\n",
    "df_pos['adjectives']=[count_adjectives(re.sub(combined_pat, ' ', text).strip().rstrip()) for text in df_pos['text']]\n",
    "df_pos['prepositions']=[count_prepositions(re.sub(combined_pat, ' ', text).strip().rstrip()) for text in df_pos['text']]\n",
    "df_pos['pronouns']=[count_pronouns(re.sub(combined_pat, ' ', text).strip().rstrip()) for text in df_pos['text']]\n",
    "df_pos['verbs']=[count_verbs(re.sub(combined_pat, ' ', text).strip().rstrip()) for text in df_pos['text']]  \n",
    "df_pos['adverb']=[count_adverbs(re.sub(combined_pat, ' ', text).strip().rstrip()) for text in df_pos['text']]\n",
    "df_pos['conjunction']=[count_conjunctions(re.sub(combined_pat, ' ', text).strip().rstrip()) for text in df_pos['text']]\n",
    "\n",
    "df_neg['nouns']=[count_nouns(re.sub(combined_pat, ' ', text).strip().rstrip()) for text in df_neg['text']]\n",
    "df_neg['adjectives']=[count_adjectives(re.sub(combined_pat, ' ', text).strip().rstrip()) for text in df_neg['text']]\n",
    "df_neg['prepositions']=[count_prepositions(re.sub(combined_pat, ' ', text).strip().rstrip()) for text in df_neg['text']]\n",
    "df_neg['pronouns']=[count_pronouns(re.sub(combined_pat, ' ', text).strip().rstrip()) for text in df_neg['text']]\n",
    "df_neg['verbs']=[count_verbs(re.sub(combined_pat, ' ', text).strip().rstrip()) for text in df_neg['text']]  \n",
    "df_neg['adverb']=[count_adverbs(re.sub(combined_pat, ' ', text).strip().rstrip()) for text in df_neg['text']]\n",
    "df_neg['conjunction']=[count_conjunctions(re.sub(combined_pat, ' ', text).strip().rstrip()) for text in df_neg['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_feature(X, feature_to_add):\n",
    "    \"\"\"\n",
    "    Returns sparse feature matrix with added feature.\n",
    "    feature_to_add can also be a list of features.\n",
    "    \"\"\"\n",
    "    from scipy.sparse import csr_matrix, hstack\n",
    "    return hstack([X, csr_matrix(feature_to_add).T], 'csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_extraction(X_train,X_test):\n",
    "    pat1 = r'@[A-Za-z0-9]+'\n",
    "    pat2 = r'https?://[A-Za-z0-9./]+'\n",
    "    pat3 = r'([@#][A-Za-z0-9]+)'\n",
    "    pat4 = r'.[A-Za-z0-9./]+'\n",
    "    combined_pat = r'|'.join((pat1, pat2,pat3,pat4))\n",
    "    temp_train = [re.sub(combined_pat, '', x) for x in X_train['text']]\n",
    "    temp_test = [re.sub(combined_pat, '', x) for x in X_test['text']]\n",
    "    #vect = CountVectorizer(min_df=5, ngram_range=(1,1)).fit(temp_train)\n",
    "    vect = TfidfVectorizer(min_df=5, ngram_range=(1,4)).fit(temp_train)\n",
    "    #vect = CountVectorizer(min_df=5, ngram_range=(1,3)).fit(temp_test)\n",
    "    X_train_chars = X_train['text'].str.len()\n",
    "    X_test_chars = X_test['text'].str.len()\n",
    "\n",
    "    X_train_digit = X_train['text'].apply(lambda x:len(re.findall(r'(\\d)',x)))\n",
    "    X_test_digit = X_test['text'].apply(lambda x:len(re.findall(r'(\\d)',x)))\n",
    "\n",
    "    X_train_URL = normalize([count_urls(text) for text in X_train['text']])\n",
    "    X_test_URL = normalize([count_urls(text) for text in X_test['text']])\n",
    "\n",
    "    #print(X_train_URL)\n",
    "    X_train_HASHTAGS = normalize([count_hashtags(text) for text in X_train['text']])\n",
    "    X_test_HASHTAGS = normalize([count_hashtags(text) for text in X_test['text']])\n",
    "\n",
    "    X_train_USERMENTION = normalize([count_user_mentions(text) for text in X_train['text']])\n",
    "    X_test_USERMENTION = normalize([count_user_mentions(text) for text in X_test['text']])\n",
    "\n",
    "    X_train_UC = normalize([count_unique_characters(text) for text in X_train['text']])\n",
    "    X_test_UC = normalize([count_unique_characters(text) for text in X_test['text']])\n",
    "\n",
    "    X_train_SC = normalize([count_special_characters(text) for text in X_train['text']])\n",
    "    X_test_SC = normalize([count_special_characters(text) for text in X_test['text']])\n",
    "\n",
    "    X_train_WORDS = normalize([count_words(text) for text in X_train['text']])\n",
    "    X_test_WORDS = normalize([count_words(text) for text in X_test['text']])\n",
    "    \n",
    "    X_train_reply = normalize(X_train['reply'])\n",
    "    X_test_reply = normalize(X_test['reply'])\n",
    "    \n",
    "    X_train_retweet = normalize(X_train['retweet'])\n",
    "    X_test_retweet = normalize(X_test['retweet'])\n",
    "    \n",
    "    X_train_likes = normalize(X_train['likes'])\n",
    "    X_test_likes = normalize(X_test['likes'])\n",
    "    \n",
    "    X_train_SW = normalize([count_slangwords(text) for text in X_train['text']])\n",
    "    X_test_SW = normalize([count_slangwords(text) for text in X_test['text']])\n",
    "    \n",
    "    X_train_STOPWORDS = normalize([count_stopwords(text) for text in X_train['text']])\n",
    "    X_test_STOPWORDS = normalize([count_stopwords(text) for text in X_test['text']])\n",
    "    \n",
    "    X_train_NOUNS = normalize(X_train['nouns'])\n",
    "    X_test_NOUNS = normalize(X_test['nouns'])\n",
    "\n",
    "    X_train_ADJECTIVES = normalize(X_train['adjectives'])\n",
    "    X_test_ADJECTIVES = normalize(X_test['adjectives'])\n",
    "    \n",
    "    X_train_PREPOSITIONS = normalize(X_train['prepositions'])\n",
    "    X_test_PREPOSITIONS = normalize(X_test['prepositions'])\n",
    "\n",
    "    X_train_PRONOUNS = normalize(X_train['pronouns'])\n",
    "    X_test_PRONOUNS = normalize(X_test['pronouns'])\n",
    "\n",
    "    X_train_VERBS = normalize(X_train['verbs'])\n",
    "    X_test_VERBS = normalize(X_test['verbs'])\n",
    "\n",
    "    X_train_ADVERBS = normalize(X_train['adverb'])\n",
    "    X_test_ADVERBS = normalize(X_test['adverb'])\n",
    "\n",
    "    X_train_CONJUNCTIONS = normalize(X_train['conjunction'])\n",
    "    X_test_CONJUNCTIONS = normalize(X_test['conjunction'])\n",
    "\n",
    "    #print(X_train_WORDS)\n",
    "\n",
    "    X_train_vectorized = vect.transform(X_train['text'])\n",
    "    X_test_vectorized = vect.transform(X_test['text'])\n",
    "\n",
    "\n",
    "    X_train_vectorized = add_feature(X_train_vectorized, [normalize(X_train_chars)])\n",
    "    X_train_vectorized = add_feature(X_train_vectorized, [normalize(X_train_digit)])\n",
    "    X_train_vectorized = add_feature(X_train_vectorized, [X_train_URL])\n",
    "    X_train_vectorized = add_feature(X_train_vectorized, [X_train_HASHTAGS])\n",
    "    X_train_vectorized = add_feature(X_train_vectorized, [X_train_USERMENTION])\n",
    "    X_train_vectorized = add_feature(X_train_vectorized, [X_train_UC])\n",
    "    X_train_vectorized = add_feature(X_train_vectorized, [X_train_SC])\n",
    "    X_train_vectorized = add_feature(X_train_vectorized, [X_train_WORDS])\n",
    "    X_train_vectorized = add_feature(X_train_vectorized, [X_train_reply])\n",
    "    X_train_vectorized = add_feature(X_train_vectorized, [X_train_retweet])\n",
    "    X_train_vectorized = add_feature(X_train_vectorized, [X_train_likes])\n",
    "    X_train_vectorized = add_feature(X_train_vectorized, [X_train_SW])\n",
    "    X_train_vectorized = add_feature(X_train_vectorized, [X_train_STOPWORDS])\n",
    "    X_train_vectorized = add_feature(X_train_vectorized, [X_train_NOUNS])\n",
    "    X_train_vectorized = add_feature(X_train_vectorized, [X_train_ADJECTIVES])\n",
    "    X_train_vectorized = add_feature(X_train_vectorized, [X_train_PREPOSITIONS])\n",
    "    X_train_vectorized = add_feature(X_train_vectorized, [X_train_PRONOUNS])\n",
    "    X_train_vectorized = add_feature(X_train_vectorized, [X_train_VERBS])\n",
    "    X_train_vectorized = add_feature(X_train_vectorized, [X_train_ADVERBS])\n",
    "    X_train_vectorized = add_feature(X_train_vectorized, [X_train_CONJUNCTIONS])\n",
    "\n",
    "    X_test_vectorized = add_feature(X_test_vectorized, [normalize(X_test_chars)])\n",
    "    X_test_vectorized = add_feature(X_test_vectorized, [normalize(X_test_digit)])\n",
    "    X_test_vectorized = add_feature(X_test_vectorized, [X_test_URL])\n",
    "    X_test_vectorized = add_feature(X_test_vectorized, [X_test_HASHTAGS])\n",
    "    X_test_vectorized = add_feature(X_test_vectorized, [X_test_USERMENTION])\n",
    "    X_test_vectorized = add_feature(X_test_vectorized, [X_test_UC])\n",
    "    X_test_vectorized = add_feature(X_test_vectorized, [X_test_SC])\n",
    "    X_test_vectorized = add_feature(X_test_vectorized, [X_test_WORDS])\n",
    "    X_test_vectorized = add_feature(X_test_vectorized, [X_test_reply])\n",
    "    X_test_vectorized = add_feature(X_test_vectorized, [X_test_retweet])\n",
    "    X_test_vectorized = add_feature(X_test_vectorized, [X_test_likes])\n",
    "    X_test_vectorized = add_feature(X_test_vectorized, [X_test_SW])\n",
    "    X_test_vectorized = add_feature(X_test_vectorized, [X_test_STOPWORDS])\n",
    "    X_test_vectorized = add_feature(X_test_vectorized, [X_test_NOUNS])\n",
    "    X_test_vectorized = add_feature(X_test_vectorized, [X_test_ADJECTIVES])\n",
    "    X_test_vectorized = add_feature(X_test_vectorized, [X_test_PREPOSITIONS])\n",
    "    X_test_vectorized = add_feature(X_test_vectorized, [X_test_PRONOUNS])\n",
    "    X_test_vectorized = add_feature(X_test_vectorized, [X_test_VERBS])\n",
    "    X_test_vectorized = add_feature(X_test_vectorized, [X_test_ADVERBS])\n",
    "    X_test_vectorized = add_feature(X_test_vectorized, [X_test_CONJUNCTIONS])\n",
    "    return (X_train_vectorized,X_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_test(df_pos,df_neg,train_index,test_index):\n",
    "    X_train = df_pos.iloc[train_index.tolist()]\n",
    "    X_train = X_train.append(df_neg.iloc[train_index.tolist()])\n",
    "    X_train.index = range(len(X_train.index))\n",
    "    \n",
    "    y_train = df_pos.target[train_index.tolist()]\n",
    "    y_train = y_train.append(df_neg.target[train_index.tolist()])\n",
    "    y_train.index = range(len(y_train.index))\n",
    "    \n",
    "    X_test = df_pos.iloc[test_index.tolist()]\n",
    "    X_test = X_test.append(df_neg.iloc[test_index.tolist()])\n",
    "    X_test.index = range(len(X_test.index))\n",
    "    \n",
    "    y_test = df_pos.target[test_index.tolist()]\n",
    "    y_test = y_test.append(df_neg.target[test_index.tolist()])\n",
    "    y_test.index = range(len(y_test.index))\n",
    "    \n",
    "    return(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=10, random_state=None, shuffle=False)\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "print(kf) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module For Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.671 \tPrecision:  0.683470098702 \tRecall:  0.66 \tROC:  0.671\n",
      "Actual Positive:  500 \tPredictedPositive(TP):  341 \tFP:  159\n",
      "Actual Negative:  500 \tPredictedNegative(TN):  330 \tFN:  170\n",
      "F-measure: 0.671530040868\n"
     ]
    }
   ],
   "source": [
    "accuracy = []\n",
    "precision= []\n",
    "recall = []\n",
    "roc = [] \n",
    "#df_pos = df_pos[0:700]\n",
    "#df_neg = df_neg[0:700]\n",
    "predictedPositive = []\n",
    "predictedNegative = []\n",
    "#counter = 0\n",
    "for train_index, test_index in kf.split(df_pos):\n",
    "    #counter = counter + 1\n",
    "    #print(\"PRocessing fold \"+str(counter))\n",
    "    X_train,y_train,X_test,y_test = get_train_test(df_pos,df_neg,train_index,test_index)\n",
    "    X_train_vectorized,X_test_vectorized = feature_extraction(X_train,X_test)\n",
    "    model = MultinomialNB(alpha=0.1)\n",
    "    model.fit(X_train_vectorized,y_train)\n",
    "    predictions = model.predict(X_test_vectorized)\n",
    "    roc.append(roc_auc_score(y_test, predictions))\n",
    "    accuracy.append(accuracy_score(y_test, predictions, normalize=True))\n",
    "    precision.append(precision_score(y_test, predictions))\n",
    "    recall.append(recall_score(y_test, predictions))\n",
    "    result = pd.DataFrame.from_items([(\"Actual\",y_test),(\"Prediction\",predictions)])\n",
    "    pp = [result['Actual'][x] for x in range(0,len(result)) if ((result['Actual'][x] ==result['Prediction'][x]) and (result['Actual'][x]==0))]\n",
    "    nn = [result['Actual'][x] for x in range(0,len(result)) if ((result['Actual'][x] ==result['Prediction'][x]) and (result['Actual'][x]==1))]\n",
    "    predictedPositive.append(len(pp))\n",
    "    predictedNegative.append(len(nn))    \n",
    "a = sum(accuracy)/10\n",
    "p = sum(precision)/10\n",
    "r = sum(recall)/10\n",
    "ro = sum(roc)/10\n",
    "print(\"Accuracy: \",a,\"\\tPrecision: \",p,\"\\tRecall: \",r,\"\\tROC: \",ro)\n",
    "TP = sum(predictedPositive)\n",
    "FP = (len(df_pos)-sum(predictedPositive))\n",
    "TN = sum(predictedNegative)\n",
    "FN = (len(df_neg)-sum(predictedNegative))\n",
    "print(\"Actual Positive: \",len(df_pos),\"\\tPredictedPositive(TP): \",TP,\"\\tFP: \",FP)\n",
    "print(\"Actual Negative: \",len(df_neg),\"\\tPredictedNegative(TN): \",TN,\"\\tFN: \",FN)\n",
    "F_measure = (2 * p * r)/(p+ r)\n",
    "print(\"F-measure: \"+str(F_measure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.583 \tPrecision:  0.588661960324 \tRecall:  0.562 \tROC:  0.583\n",
      "Actual Positive:  500 \tPredictedPositive(TP):  302 \tFP:  198\n",
      "Actual Negative:  500 \tPredictedNegative(TN):  281 \tFN:  219\n",
      "F-measure: 0.575022088345\n"
     ]
    }
   ],
   "source": [
    "accuracy = []\n",
    "precision= []\n",
    "recall = []\n",
    "roc = [] \n",
    "#df_pos = df_pos[0:700]\n",
    "#df_neg = df_neg[0:700]\n",
    "predictedPositive = []\n",
    "predictedNegative = []\n",
    "for train_index, test_index in kf.split(df_pos):\n",
    "    X_train,y_train,X_test,y_test = get_train_test(df_pos,df_neg,train_index,test_index)\n",
    "    X_train_vectorized,X_test_vectorized = feature_extraction(X_train,X_test)\n",
    "    model = DecisionTreeClassifier()\n",
    "    model.fit(X_train_vectorized,y_train)\n",
    "    predictions = model.predict(X_test_vectorized)\n",
    "    roc.append(roc_auc_score(y_test, predictions))\n",
    "    accuracy.append(accuracy_score(y_test, predictions, normalize=True))\n",
    "    precision.append(precision_score(y_test, predictions))\n",
    "    recall.append(recall_score(y_test, predictions))\n",
    "    result = pd.DataFrame.from_items([(\"Actual\",y_test),(\"Prediction\",predictions)])\n",
    "    pp = [result['Actual'][x] for x in range(0,len(result)) if ((result['Actual'][x] ==result['Prediction'][x]) and (result['Actual'][x]==0))]\n",
    "    nn = [result['Actual'][x] for x in range(0,len(result)) if ((result['Actual'][x] ==result['Prediction'][x]) and (result['Actual'][x]==1))]\n",
    "    predictedPositive.append(len(pp))\n",
    "    predictedNegative.append(len(nn))    \n",
    "a = sum(accuracy)/10\n",
    "p = sum(precision)/10\n",
    "r = sum(recall)/10\n",
    "ro = sum(roc)/10\n",
    "print(\"Accuracy: \",a,\"\\tPrecision: \",p,\"\\tRecall: \",r,\"\\tROC: \",ro)\n",
    "TP = sum(predictedPositive)\n",
    "FP = (len(df_pos)-sum(predictedPositive))\n",
    "TN = sum(predictedNegative)\n",
    "FN = (len(df_neg)-sum(predictedNegative))\n",
    "print(\"Actual Positive: \",len(df_pos),\"\\tPredictedPositive(TP): \",TP,\"\\tFP: \",FP)\n",
    "print(\"Actual Negative: \",len(df_neg),\"\\tPredictedNegative(TN): \",TN,\"\\tFN: \",FN)\n",
    "F_measure = (2 * p * r)/(p+ r)\n",
    "print(\"F-measure: \"+str(F_measure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.674 \tPrecision:  0.658631261738 \tRecall:  0.746 \tROC:  0.674\n",
      "Actual Positive:  500 \tPredictedPositive(TP):  301 \tFP:  199\n",
      "Actual Negative:  500 \tPredictedNegative(TN):  373 \tFN:  127\n",
      "F-measure: 0.699598442154\n"
     ]
    }
   ],
   "source": [
    "accuracy = []\n",
    "precision= []\n",
    "recall = []\n",
    "roc = [] \n",
    "#df_pos = df_pos[0:700]\n",
    "#df_neg = df_neg[0:700]\n",
    "predictedPositive = []\n",
    "predictedNegative = []\n",
    "for train_index, test_index in kf.split(df_pos):\n",
    "    X_train,y_train,X_test,y_test = get_train_test(df_pos,df_neg,train_index,test_index)\n",
    "    X_train_vectorized,X_test_vectorized = feature_extraction(X_train,X_test)\n",
    "    #model = SVC(C=10000)\n",
    "    #model = SVC (C=10000, kernel='rbf', degree=3, gamma='auto')\n",
    "    #model = SVC (C=1000, kernel='poly', degree=3, gamma='auto')\n",
    "    #model = SVC (C=1000, kernel='linear', degree=3, gamma='auto')\n",
    "    #model = SVC (C=1000, kernel='sigmoid', degree=3, gamma='auto')\n",
    "    model = SVC (C=1.0,  kernel='rbf',gamma=0.10000000000000001)\n",
    "    #model = SVC (C=100)\n",
    "    #model = SVC (C=100, kernel='rbf', degree=3, gamma='auto')\n",
    "    model.fit(X_train_vectorized,y_train)\n",
    "    predictions = model.predict(X_test_vectorized)\n",
    "    roc.append(roc_auc_score(y_test, predictions))\n",
    "    accuracy.append(accuracy_score(y_test, predictions, normalize=True))\n",
    "    precision.append(precision_score(y_test, predictions))\n",
    "    recall.append(recall_score(y_test, predictions))\n",
    "    result = pd.DataFrame.from_items([(\"Actual\",y_test),(\"Prediction\",predictions)])\n",
    "    pp = [result['Actual'][x] for x in range(0,len(result)) if ((result['Actual'][x] ==result['Prediction'][x]) and (result['Actual'][x]==0))]\n",
    "    nn = [result['Actual'][x] for x in range(0,len(result)) if ((result['Actual'][x] ==result['Prediction'][x]) and (result['Actual'][x]==1))]\n",
    "    predictedPositive.append(len(pp))\n",
    "    predictedNegative.append(len(nn))    \n",
    "a = sum(accuracy)/10\n",
    "p = sum(precision)/10\n",
    "r = sum(recall)/10\n",
    "ro = sum(roc)/10\n",
    "print(\"Accuracy: \",a,\"\\tPrecision: \",p,\"\\tRecall: \",r,\"\\tROC: \",ro)\n",
    "TP = sum(predictedPositive)\n",
    "FP = (len(df_pos)-sum(predictedPositive))\n",
    "TN = sum(predictedNegative)\n",
    "FN = (len(df_neg)-sum(predictedNegative))\n",
    "print(\"Actual Positive: \",len(df_pos),\"\\tPredictedPositive(TP): \",TP,\"\\tFP: \",FP)\n",
    "print(\"Actual Negative: \",len(df_neg),\"\\tPredictedNegative(TN): \",TN,\"\\tFN: \",FN)\n",
    "F_measure = (2 * p * r)/(p+ r)\n",
    "print(\"F-measure: \"+str(F_measure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.628 \tPrecision:  0.626711107124 \tRecall:  0.642 \tROC:  0.628\n",
      "Actual Positive:  500 \tPredictedPositive(TP):  307 \tFP:  193\n",
      "Actual Negative:  500 \tPredictedNegative(TN):  321 \tFN:  179\n",
      "F-measure: 0.634263432415\n"
     ]
    }
   ],
   "source": [
    "accuracy = []\n",
    "precision= []\n",
    "recall = []\n",
    "roc = [] \n",
    "#df_pos = df_pos[0:700]\n",
    "#df_neg = df_neg[0:700]\n",
    "predictedPositive = []\n",
    "predictedNegative = []\n",
    "for train_index, test_index in kf.split(df_pos):\n",
    "    X_train,y_train,X_test,y_test = get_train_test(df_pos,df_neg,train_index,test_index)\n",
    "    X_train_vectorized,X_test_vectorized = feature_extraction(X_train,X_test)\n",
    "    #model = LogisticRegression(C=100)\n",
    "    #model = LogisticRegression(C=100, penalty='l1')\n",
    "    model = LogisticRegression(C=100, penalty='l2')\n",
    "    model.fit(X_train_vectorized,y_train)\n",
    "    predictions = model.predict(X_test_vectorized)\n",
    "    roc.append(roc_auc_score(y_test, predictions))\n",
    "    accuracy.append(accuracy_score(y_test, predictions, normalize=True))\n",
    "    precision.append(precision_score(y_test, predictions))\n",
    "    recall.append(recall_score(y_test, predictions))\n",
    "    ################################################\n",
    "    #cm = confusion_matrix(y_test, predictions)\n",
    "    #print(cm)\n",
    "    #################################################\n",
    "    result = pd.DataFrame.from_items([(\"Actual\",y_test),(\"Prediction\",predictions)])\n",
    "    pp = [result['Actual'][x] for x in range(0,len(result)) if ((result['Actual'][x] ==result['Prediction'][x]) and (result['Actual'][x]==0))]\n",
    "    nn = [result['Actual'][x] for x in range(0,len(result)) if ((result['Actual'][x] ==result['Prediction'][x]) and (result['Actual'][x]==1))]\n",
    "    predictedPositive.append(len(pp))\n",
    "    predictedNegative.append(len(nn))   \n",
    "    ##############################################################################################\n",
    "    #print(\"Actual Positive: \",str(len(predictions)/2),\"\\tPredictedPositive(TP): \",str(len(pp)))\n",
    "    #print(\"Actual Negative: \",str(len(predictions)/2),\"\\tPredictedNegative(TN): \",str(len(nn)))\n",
    "    ###############################################################################################\n",
    "a = sum(accuracy)/10\n",
    "p = sum(precision)/10\n",
    "r = sum(recall)/10\n",
    "ro = sum(roc)/10\n",
    "print(\"Accuracy: \",a,\"\\tPrecision: \",p,\"\\tRecall: \",r,\"\\tROC: \",ro)\n",
    "TP = sum(predictedPositive)\n",
    "FP = (len(df_pos)-sum(predictedPositive))\n",
    "TN = sum(predictedNegative)\n",
    "FN = (len(df_neg)-sum(predictedNegative))\n",
    "print(\"Actual Positive: \",len(df_pos),\"\\tPredictedPositive(TP): \",TP,\"\\tFP: \",FP)\n",
    "print(\"Actual Negative: \",len(df_neg),\"\\tPredictedNegative(TN): \",TN,\"\\tFN: \",FN)\n",
    "F_measure = (2 * p * r)/(p+ r)\n",
    "print(\"F-measure: \"+str(F_measure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.width',2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@kpsharmaoli ओलीले कार्यकर्तालाई भने- पीडितको घरमा पाहुना नबन्नुस् #NepalEarthquake https://shar.es/1rI8n7\\xa0pic.twitter.com/Uuus55ifhv '"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pos['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'कतारले नेपाली कामदारलाइ किरिया गर्न पनि घर जान दिएन http://goo.gl/CGkrLY\\xa0 #NepalEarthquake #NepalRelief #NepalQuakeRelief '"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_neg['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
